"""
æ€¥æ€§ç¼ºè¡€æ€§å’ä¸­æœºæ¢°å–æ “æ‚£è€…90å¤©é¢„åé¢„æµ‹è®¡ç®—å™¨
åŸºäºStreamlitå’ŒSHAPçš„ç½‘é¡µåº”ç”¨
ç‰ˆæœ¬ï¼š1.3 (ç€‘å¸ƒå›¾ä¼˜åŒ–ç‰ˆ)
"""

import streamlit as st
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap

# ==================== åº”ç”¨åˆå§‹åŒ– ====================
st.set_page_config(page_title="å’ä¸­é¢„åé¢„æµ‹è®¡ç®—å™¨", layout="wide")
st.title("è„‘å’ä¸­æœºæ¢°å–æ “æ‚£è€…å‘ç—…90å¤©é¢„åæƒ…å†µé¢„æµ‹")
st.markdown("""
æ­¤å·¥å…·åŸºäºè®­ç»ƒçš„éšæœºæ£®æ—æ¨¡å‹ï¼Œæ ¹æ®æ‚£è€…çš„ä¸´åºŠç‰¹å¾é¢„æµ‹å…¶å‘ç—…å90å¤©çš„é¢„åæƒ…å†µã€‚
**å…è´£å£°æ˜**ï¼šæœ¬å·¥å…·æ—¨åœ¨è¾…åŠ©ä¸´åºŠæ²»ç–—ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—åˆ¤æ–­ã€‚
""")

# ==================== ç‰¹å¾é…ç½®å­—å…¸ ====================
FEATURE_CONFIG = {
    'Age': ('å¹´é¾„ (å²)', {'type': 'number', 'min_value': 18, 'max_value': 120, 'value': 65, 'step': 1}),
    'P': ('è„‰æ/å¿ƒç‡ (æ¬¡/åˆ†)', {'type': 'number', 'min_value': 30, 'max_value': 200, 'value': 85, 'step': 1}),
    'NIHSS': ('NIHSSè¯„åˆ†', {'type': 'number', 'min_value': 0, 'max_value': 42, 'value': 10, 'step': 1}),
    'PNT': ('ç©¿åˆºåˆ°å†é€šæ—¶é—´ (åˆ†é’Ÿ)', {'type': 'number', 'min_value': 0, 'max_value': 500, 'value': 220, 'step': 10}),
    'NEUT': ('ä¸­æ€§ç²’ç»†èƒè®¡æ•° (10^9/L)', {'type': 'number', 'min_value': 0.0, 'max_value': 50.0, 'value': 7.0, 'step': 0.1}),
    'D-dimer': ('D-äºŒèšä½“ (mg/L)', {'type': 'number', 'min_value': 0.0, 'max_value': 20.0, 'value': 0.5, 'step': 0.1}),
    'NLR': ('ä¸­æ€§ç²’ç»†èƒ-æ·‹å·´ç»†èƒæ¯”å€¼ (NLR)', {'type': 'number', 'min_value': 0.0, 'max_value': 50.0, 'value': 3.0, 'step': 0.1}),
    'Barthel Index Score': ('BarthelæŒ‡æ•°', {'type': 'number', 'min_value': 0, 'max_value': 100, 'value': 60, 'step': 5}),
    'NRS2002 Score': ('NRS2002è¥å…»é£é™©è¯„åˆ†', {'type': 'number', 'min_value': 0, 'max_value': 7, 'value': 3, 'step': 1}),
    'Dysphagia': ('å…¥é™¢æ—¶åå’½å›°éš¾', {'type': 'select', 'options': ['æ— ', 'æœ‰'], 'index': 0}),
}

# ==================== åŠ è½½æ¨¡å‹ä¸æ•°æ® ====================
@st.cache_resource
def load_model_and_explainer():
    """ç¼“å­˜åŠ è½½æ¨¡å‹å’ŒSHAPè§£é‡Šå™¨"""
    try:
        model_data = joblib.load('./model.joblib')
        model = model_data['model']
        
        # æå–ç‰¹å¾å
        if 'feature_names' in model_data:
            model_feature_names = model_data['feature_names']
        elif 'features' in model_data:
            model_feature_names = model_data['features']
        else:
            model_feature_names = list(FEATURE_CONFIG.keys())
        
        # éªŒè¯ç‰¹å¾é…ç½®
        missing_features = [f for f in model_feature_names if f not in FEATURE_CONFIG]
        if missing_features:
            st.error(f"âŒ ç‰¹å¾é…ç½®ç¼ºå¤±ï¼š{missing_features}")
            st.stop()
        
        # åŠ è½½æ•°æ®ç”¨äºSHAPèƒŒæ™¯
        df = pd.read_excel('./data.xlsx')
        X_background = df[model_feature_names]
        
        # åˆ›å»ºSHAPè§£é‡Šå™¨
        sample_size = min(50, len(X_background))
        background_data = X_background.sample(sample_size, random_state=42)
        explainer = shap.TreeExplainer(model, data=background_data)
        
        return model, model_feature_names, explainer, model_data
        
    except Exception as e:
        st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
        raise

# å°è¯•åŠ è½½æ¨¡å‹
try:
    model, model_feature_names, shap_explainer, model_metadata = load_model_and_explainer()
    st.sidebar.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    st.sidebar.info(f"å·²åŠ è½½ {len(model_feature_names)} ä¸ªç‰¹å¾")
except Exception as e:
    st.sidebar.error(f"âŒ åŠ è½½å¤±è´¥: {e}")
    st.stop()

# ==================== ä¾§è¾¹æ è¾“å…¥ç•Œé¢ ====================
st.sidebar.header("ğŸ”¬ è¾“å…¥æ‚£è€…ä¸´åºŠç‰¹å¾")
user_inputs = {}

for feature_name in model_feature_names:
    if feature_name in FEATURE_CONFIG:
        label, config = FEATURE_CONFIG[feature_name]
        
        if config['type'] == 'number':
            user_input = st.sidebar.number_input(
                label=label,
                min_value=config.get('min_value', 0),
                max_value=config.get('max_value', 100),
                value=config.get('value', 0),
                step=config.get('step', 1),
                key=f"input_{feature_name}"
            )
            user_inputs[feature_name] = user_input
            
        elif config['type'] == 'select' and feature_name == 'Dysphagia':
            display_value = st.sidebar.selectbox(
                label=label,
                options=config['options'],
                index=config['index'],
                key=f"select_{feature_name}"
            )
            user_inputs[feature_name] = 1 if display_value == 'æœ‰' else 0

# ==================== é¢„æµ‹æ‰§è¡Œ ====================
if st.sidebar.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
    with st.spinner('æ¨¡å‹è®¡ç®—ä¸­...'):
        
        # 1. å‡†å¤‡è¾“å…¥æ•°æ®
        input_df = pd.DataFrame([user_inputs], columns=model_feature_names)
        
        # 2. è·å–é¢„æµ‹æ¦‚ç‡
        proba = model.predict_proba(input_df)[0]
        good_prob = proba[0] * 100
        poor_prob = proba[1] * 100
        
        # 3. æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.header("ğŸ“Š é¢„æµ‹ç»“æœ")
        col1, col2 = st.columns(2)
        with col1:
            progress_value = max(0.0, min(good_prob / 100.0, 1.0))
            st.metric(
                label="**è‰¯å¥½é¢„åæ¦‚ç‡ (mRS 0-2)**",
                value=f"{good_prob:.1f}%",
                delta=f"{good_prob-50:.1f}%" if good_prob >= 50 else f"{good_prob-50:.1f}%"
            )
            st.progress(progress_value)
        with col2:
            progress_value = max(0.0, min(poor_prob / 100.0, 1.0))
            st.metric(
                label="**ä¸è‰¯é¢„åæ¦‚ç‡ (mRS 3-6)**",
                value=f"{poor_prob:.1f}%",
                delta=f"{poor_prob-50:.1f}%" if poor_prob >= 50 else f"{poor_prob-50:.1f}%",
                delta_color="inverse"
            )
            st.progress(progress_value)
        
        # 4. ä¸´åºŠè§£è¯»
        st.subheader("ğŸ§­ ä¸´åºŠè§£è¯»")
        if good_prob >= 70:
            st.success(f"**é«˜å¯èƒ½æ€§è‰¯å¥½é¢„å** ({good_prob:.1f}%) - è¯¥æ‚£è€…æœ‰è¾ƒé«˜æ¦‚ç‡è·å¾—è‰¯å¥½åŠŸèƒ½æ¢å¤ã€‚")
        elif good_prob >= 40:
            st.warning(f"**ä¸­ç­‰å¯èƒ½æ€§è‰¯å¥½é¢„å** ({good_prob:.1f}%) - éœ€å¯†åˆ‡ç›‘æµ‹ä¸ç§¯æå¹²é¢„ã€‚")
        else:
            st.error(f"**é«˜é£é™©ä¸è‰¯é¢„å** ({poor_prob:.1f}%) - å»ºè®®é‡‡å–å¼ºåŒ–ä¸´åºŠç®¡ç†ç­–ç•¥ã€‚")
        
        # ==================== SHAPè§£é‡Šéƒ¨åˆ† ====================
        st.header("ğŸ” æ¨¡å‹è§£é‡Šåˆ†æ")
        
        # è®¡ç®—SHAPå€¼
        try:
            shap_values = shap_explainer(input_df)
            
            # æå–åŸºå‡†å€¼
            if isinstance(shap_explainer.expected_value, (list, np.ndarray)):
                base_value = float(shap_explainer.expected_value[1])
            else:
                base_value = float(shap_explainer.expected_value)
            
            # æå–å½“å‰æ ·æœ¬çš„SHAPå€¼
            shap_vals = None
            
            if hasattr(shap_values, 'values'):
                if len(shap_values.values.shape) == 3:
                    shap_vals = shap_values.values[0, :, 1]
                else:
                    shap_vals = shap_values.values[0, :]
            elif isinstance(shap_values, list) and len(shap_values) == 2:
                shap_vals = shap_values[1][0, :]
            else:
                shap_vals = np.array(shap_values).flatten()
            
            shap_vals = np.array(shap_vals).flatten()
            final_prediction = base_value + shap_vals.sum()
            
        except Exception as e:
            st.error(f"âŒ è®¡ç®—SHAPå€¼æ—¶å‡ºé”™: {str(e)}")
            shap_vals = np.zeros(len(model_feature_names))
            base_value = 0.5
            final_prediction = 0.5
        
        # 5. åˆ›å»ºSHAPç€‘å¸ƒå›¾ï¼ˆå·²ç§»é™¤æ‰€æœ‰æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾ï¼‰
        st.subheader("ğŸ“ˆ ç‰¹å¾è´¡çŒ®ç€‘å¸ƒå›¾")
        st.markdown("""
        æ­¤å›¾å±•ç¤ºäº†å„ç‰¹å¾å¦‚ä½•å½±å“é¢„æµ‹ç»“æœã€‚ä»**åŸºå‡†é£é™©**å¼€å§‹ï¼Œæ¯ä¸ªç‰¹å¾çš„è´¡çŒ®ï¼ˆæ­£å€¼å¢åŠ é£é™©ï¼Œè´Ÿå€¼é™ä½é£é™©ï¼‰ä¾æ¬¡ç´¯åŠ ï¼Œå¾—åˆ°**æœ€ç»ˆé¢„æµ‹å€¼**ã€‚
        """)
        
        try:
            # åˆ›å»ºSHAP Explanationå¯¹è±¡
            explanation = shap.Explanation(
                values=shap_vals,
                base_values=base_value,
                data=input_df.iloc[0].values,
                feature_names=model_feature_names
            )
            
            # ç»˜åˆ¶ç€‘å¸ƒå›¾
            fig, ax = plt.subplots(figsize=(12, 8))
            shap.waterfall_plot(explanation, max_display=len(model_feature_names), show=False)
            
            # ç§»é™¤æ‰€æœ‰åæ ‡è½´æ ‡ç­¾ï¼Œåªä¿ç•™æœ€ç®€æ´çš„å›¾è¡¨
            ax.set_xlabel('')  # ç§»é™¤Xè½´æ ‡ç­¾
            ax.set_ylabel('')  # ç§»é™¤Yè½´æ ‡ç­¾
            
            plt.tight_layout()
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"âŒ ç”Ÿæˆç€‘å¸ƒå›¾æ—¶å‡ºé”™: {str(e)}")
            st.info("å°è¯•æ˜¾ç¤ºç®€åŒ–çš„ç‰¹å¾è´¡çŒ®è¡¨æ ¼...")
        
        # ç€‘å¸ƒå›¾è§£è¯»
        with st.expander("ğŸ’¡ å¦‚ä½•è§£è¯»ç€‘å¸ƒå›¾ï¼Ÿ", expanded=False):
            st.markdown(f"""
            **å›¾è¡¨å…ƒç´ è§£è¯»ï¼š**
            1.  **E[f(X)] = {base_value:.3f}** - åŸºå‡†é£é™©ï¼Œä»£è¡¨æ‚£è€…ç¾¤ä½“çš„å¹³å‡é£é™©æ°´å¹³
            2.  **æ¯è¡Œä¸€ä¸ªç‰¹å¾** - æ˜¾ç¤ºè¯¥ç‰¹å¾å¯¹é¢„æµ‹çš„å…·ä½“è´¡çŒ®
            3.  **æ¡å½¢æ–¹å‘**ï¼š
                - ğŸ”´ **çº¢è‰²ï¼ˆå‘å³ï¼‰**ï¼šå¢åŠ ä¸è‰¯é¢„åé£é™©
                - ğŸ”µ **è“è‰²ï¼ˆå‘å·¦ï¼‰**ï¼šé™ä½ä¸è‰¯é¢„åé£é™©
            4.  **æ¡å½¢é•¿åº¦**ï¼šè´¡çŒ®çš„ç»å¯¹å€¼å¤§å°
            5.  **f(x) = {final_prediction:.3f}** - æœ¬æ¬¡é¢„æµ‹çš„æœ€ç»ˆé€»è¾‘å€¼
            
            **ä¸´åºŠæ„ä¹‰**ï¼šçº¢è‰²æ¡çš„ç‰¹å¾æ˜¯é£é™©å› ç´ ï¼Œè“è‰²æ¡çš„æ˜¯ä¿æŠ¤å› ç´ ã€‚
            """)
        
        # 6. ç‰¹å¾è´¡çŒ®åº¦è¡¨æ ¼
        st.subheader("ğŸ“‹ ç‰¹å¾è´¡çŒ®åº¦æ˜ç»†")
        
        try:
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            table_data = []
            for i, feat_name in enumerate(model_feature_names):
                feat_label = FEATURE_CONFIG[feat_name][0]
                contribution = shap_vals[i]
                abs_contrib = abs(contribution)
                
                table_data.append({
                    'ä¸´åºŠç‰¹å¾': feat_label,
                    'è´¡çŒ®å€¼': contribution,
                    'ç»å¯¹å€¼': abs_contrib,
                    'æ–¹å‘': 'ğŸ”´ å¢åŠ é£é™©' if contribution > 0 else 'ğŸ”µ é™ä½é£é™©'
                })
            
            # æŒ‰ç»å¯¹å€¼æ’åº
            contrib_df = pd.DataFrame(table_data)
            contrib_df = contrib_df.sort_values('ç»å¯¹å€¼', ascending=False).reset_index(drop=True)
            
            # æ˜¾ç¤ºè¡¨æ ¼
            st.dataframe(
                contrib_df.style.format({'è´¡çŒ®å€¼': '{:+.4f}', 'ç»å¯¹å€¼': '{:.4f}'}),
                use_container_width=True,
                hide_index=True
            )
            
        except Exception as e:
            st.error(f"âŒ ç”Ÿæˆè´¡çŒ®åº¦è¡¨æ ¼æ—¶å‡ºé”™: {str(e)}")
        
        # 7. è¾“å…¥æ•°æ®å›é¡¾
        with st.expander("ğŸ“ æŸ¥çœ‹æœ¬æ¬¡è¾“å…¥çš„è¯¦ç»†æ•°æ®", expanded=False):
            try:
                review_data = []
                for feat_name in model_feature_names:
                    feat_label = FEATURE_CONFIG[feat_name][0]
                    raw_value = user_inputs[feat_name]
                    
                    if feat_name == 'Dysphagia':
                        disp_value = 'æœ‰' if raw_value == 1 else 'æ— '
                    else:
                        disp_value = raw_value
                    
                    review_data.append({
                        'ä¸´åºŠç‰¹å¾': feat_label,
                        'è¾“å…¥å€¼': disp_value
                    })
                
                review_df = pd.DataFrame(review_data)
                st.dataframe(review_df, use_container_width=True, hide_index=True)
                
            except Exception as e:
                st.error(f"âŒ æ˜¾ç¤ºè¾“å…¥æ•°æ®æ—¶å‡ºé”™: {str(e)}")

# ==================== é¡µè„šä¿¡æ¯ ====================
st.sidebar.markdown("---")
st.sidebar.markdown("### â„¹ï¸ ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("""
1. åœ¨å·¦ä¾§è¾“å…¥æ‚£è€…ä¸´åºŠç‰¹å¾
2. ç‚¹å‡» **ğŸš€ å¼€å§‹é¢„æµ‹** æŒ‰é’®
3. æŸ¥çœ‹å³ä¾§é¢„æµ‹ç»“æœå’Œè§£é‡Š
""")

st.sidebar.markdown("---")
model_name = model_metadata.get('model_name', 'Random Forest')
training_date = model_metadata.get('training_date', 'æœªçŸ¥æ—¥æœŸ')
st.sidebar.caption(f"**æ¨¡å‹ä¿¡æ¯**ï¼š{model_name} | è®­ç»ƒæ—¥æœŸï¼š{training_date}")
st.sidebar.caption("å¼€å‘æ¡†æ¶ï¼šStreamlit + SHAP")

# ==================== åº”ç”¨è¯´æ˜ ====================
with st.expander("ğŸ“– å…³äºæ­¤è®¡ç®—å™¨", expanded=False):
    st.markdown("""
    ### æ¨¡å‹èƒŒæ™¯
    - **ç®—æ³•**ï¼šéšæœºæ£®æ—åˆ†ç±»å™¨
    - **ç›®æ ‡å˜é‡**ï¼š90å¤©æ”¹è‰¯Rankiné‡è¡¨è¯„åˆ† (mRS)
    - **åˆ†ç±»**ï¼šè‰¯å¥½é¢„å (mRS 0-2) vs ä¸è‰¯é¢„å (mRS 3-6)
    
    ### æŠ€æœ¯æ¶æ„
    - **å‰ç«¯ç•Œé¢**ï¼šStreamlit
    - **æ¨¡å‹è§£é‡Š**ï¼šSHAP
    - **éƒ¨ç½²å¹³å°**ï¼šStreamlit Community Cloud
    
    ### æ³¨æ„äº‹é¡¹
    1. æœ¬å·¥å…·é€‚ç”¨äº**ç ”ç©¶ç›®çš„**ï¼Œä¸´åºŠå†³ç­–éœ€ç»“åˆåŒ»ç”Ÿä¸“ä¸šåˆ¤æ–­
    2. æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å¤–å¯èƒ½è¡¨ç°ä¸ä½³
    3. å®šæœŸéªŒè¯å’Œæ›´æ–°æ¨¡å‹æ˜¯å¿…è¦çš„
    """)